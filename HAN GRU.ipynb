{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evandro/myenv2/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed, Dropout\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk import tokenize\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    Hierarchial Attention Layer as described by Hierarchical Attention Networks for Document Classification(2016)\n",
    "    - Yang et. al.\n",
    "    Source: https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "    Theano backend\n",
    "    \"\"\"\n",
    "    def __init__(self,attention_dim=100,return_coefficients=False,**kwargs):\n",
    "        # Initializer \n",
    "        self.supports_masking = True\n",
    "        self.return_coefficients = return_coefficients\n",
    "        self.init = initializers.get('glorot_uniform') # initializes values with uniform distribution\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Builds all weights\n",
    "        # W = Weight matrix, b = bias vector, u = context vector\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)),name='W')\n",
    "        self.b = K.variable(self.init((self.attention_dim, )),name='b')\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)),name='u')\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, hit, mask=None):\n",
    "        # Here, the actual calculation is done\n",
    "        uit = K.bias_add(K.dot(hit, self.W),self.b)\n",
    "        uit = K.tanh(uit)\n",
    "        \n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "        ait = K.exp(ait)\n",
    "        \n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = hit * ait\n",
    "        \n",
    "        if self.return_coefficients:\n",
    "            return [K.sum(weighted_input, axis=1), ait]\n",
    "        else:\n",
    "            return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_coefficients:\n",
    "            return [(input_shape[0], input_shape[-1]), (input_shape[0], input_shape[-1], 1)]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_NUM = 95\n",
    "MAX_WORD_NUM = 55\n",
    "MAX_FEATURES = 200000 \n",
    "EMBED_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"fakebr.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text', 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['category']\n",
    "text = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(\"\\\\n\", \" \", string)\n",
    "    string = re.sub('\\+\\xa0', \" \", string)\n",
    "    string = re.sub(\"\\xa0\", \" \", string)\n",
    "    #string = re.sub(r\"\\u\", \" \", string)\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\'\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)  \n",
    "\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = []\n",
    "labels = []\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lens = []\n",
    "sent_nums = []\n",
    "for idx in range(df.text.shape[0]):\n",
    "    text = clean_str(df.text[idx])\n",
    "    texts.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    sent_nums.append(len(sentences))\n",
    "    for sent in sentences:\n",
    "        sent_lens.append(len(text_to_word_sequence(sent)))\n",
    "    paras.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES, oov_token=True)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((len(texts), MAX_SENTENCE_NUM, MAX_WORD_NUM), dtype='int64')\n",
    "for i, sentences in enumerate(paras):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j< MAX_SENTENCE_NUM:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                try:\n",
    "                    if k<MAX_WORD_NUM and tokenizer.word_index[word]<MAX_FEATURES:\n",
    "                        data[i,j,k] = tokenizer.word_index[word]\n",
    "                        k=k+1\n",
    "                except:\n",
    "                    print(word)\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.197674524355197 29.838632511480565\n",
      "30.543333333333333 67.88308773177603\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(sent_lens),2*np.std(sent_lens))\n",
    "print(np.mean(sent_nums),2*np.std(sent_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 98358 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (7200, 95, 55)\n",
      "Shape of labels tensor: (7200, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of labels tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r$\n",
      "00\n",
      "三藏法師玄奘奉\n",
      "r$\n",
      "Total 929594 word vectors.\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = \"../embeddings/glove_s100.txt\"\n",
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR)\n",
    "for line in f:\n",
    "    try:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        print(word)\n",
    "        pass\n",
    "f.close()\n",
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 21097 which is 21.45 % of total words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "        \n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and len(embedding_vector) == 100:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def han():\n",
    "    \"\"\"\n",
    "    Create Keras functional model for hierarchical attention network\n",
    "    \"\"\"\n",
    "    embedding_layer = Embedding(len(word_index) + 1,EMBED_SIZE,weights=[embedding_matrix], input_length=MAX_WORD_NUM, trainable=False,name='word_embedding')\n",
    "\n",
    "    # Words level attention model\n",
    "    word_input = Input(shape=(MAX_WORD_NUM,), dtype='int32',name='word_input')\n",
    "    word_sequences = embedding_layer(word_input)\n",
    "    word_gru = Bidirectional(GRU(50, return_sequences=True),name='word_gru')(word_sequences)\n",
    "    word_dense = Dense(100, activation='relu', name='word_dense')(word_gru) \n",
    "    word_att,word_coeffs = AttentionLayer(EMBED_SIZE,True,name='word_attention')(word_dense)\n",
    "    wordEncoder = Model(inputs = word_input,outputs = word_att)\n",
    "\n",
    "    # Sentence level attention model\n",
    "    sent_input = Input(shape=(MAX_SENTENCE_NUM,MAX_WORD_NUM), dtype='int32',name='sent_input')\n",
    "    sent_encoder = TimeDistributed(wordEncoder,name='sent_linking')(sent_input)\n",
    "    sent_gru = Bidirectional(GRU(50, return_sequences=True),name='sent_gru')(sent_encoder)\n",
    "    sent_dense = Dense(100, activation='relu', name='sent_dense')(sent_gru) \n",
    "    sent_att,sent_coeffs = AttentionLayer(EMBED_SIZE,return_coefficients=True,name='sent_attention')(sent_dense)\n",
    "    sent_drop = Dropout(0.5,name='sent_dropout')(sent_att)\n",
    "    preds = Dense(2, activation='softmax',name='output')(sent_drop)\n",
    "\n",
    "    # Model compile\n",
    "    model = Model(sent_input, preds)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['categorical_accuracy'])\n",
    "    print(wordEncoder.summary())\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state= 0)\n",
    "\n",
    "es = EarlyStopping(monitor = 'loss', min_delta = 1e-3, patience = 10) # Monitora a funcao de loss e se em 10 epocas ela nao melhorar em pelo menos 1e-3 o treinamento termina\n",
    "rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5) # Diminui a taxa de aprendizagem se ficar 5 epocas sem melhorar o loss\n",
    "mcp = ModelCheckpoint(filepath = 'pesos.h5', monitor = 'loss', save_best_only = True, verbose = 1) # Salva o melhor modelo que encontrar\n",
    "\n",
    "classificador = KerasClassifier(build_fn = han, epochs = 2, batch_size = 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#resultados = cross_val_score(estimator = classificador,\n",
    "#                             X = data, y = categories.values,\n",
    "#                             cv =5, scoring = 'accuracy', \n",
    "#                             fit_params= {'callbacks': [es, rlr]}\n",
    "#                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "labels_dummy = to_categorical(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(skf.split(data, categories))\n",
    "checkpoint = ModelCheckpoint('best_model.h5', verbose=0, monitor='val_loss',save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "word_input (InputLayer)      (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "word_embedding (Embedding)   (None, 55, 100)           9835900   \n",
      "_________________________________________________________________\n",
      "word_gru (Bidirectional)     (None, 55, 100)           45300     \n",
      "_________________________________________________________________\n",
      "word_dense (Dense)           (None, 55, 100)           10100     \n",
      "_________________________________________________________________\n",
      "word_attention (AttentionLay [(None, 100), (None, 100, 10200     \n",
      "=================================================================\n",
      "Total params: 9,901,500\n",
      "Trainable params: 65,600\n",
      "Non-trainable params: 9,835,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sent_input (InputLayer)      (None, 95, 55)            0         \n",
      "_________________________________________________________________\n",
      "sent_linking (TimeDistribute (None, 95, 100)           9901500   \n",
      "_________________________________________________________________\n",
      "sent_gru (Bidirectional)     (None, 95, 100)           45300     \n",
      "_________________________________________________________________\n",
      "sent_dense (Dense)           (None, 95, 100)           10100     \n",
      "_________________________________________________________________\n",
      "sent_attention (AttentionLay [(None, 100), (None, 100, 10200     \n",
      "_________________________________________________________________\n",
      "sent_dropout (Dropout)       (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 9,967,302\n",
      "Trainable params: 131,402\n",
      "Non-trainable params: 9,835,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Fold  0\n",
      "WARNING:tensorflow:From /home/evandro/myenv2/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 5760 samples, validate on 1440 samples\n",
      "Epoch 1/100\n",
      "5760/5760 [==============================] - 104s 18ms/step - loss: 0.5716 - categorical_accuracy: 0.5595 - val_loss: 0.4950 - val_categorical_accuracy: 0.8729\n",
      "Epoch 2/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.3964 - categorical_accuracy: 0.8847 - val_loss: 0.2353 - val_categorical_accuracy: 0.9292\n",
      "Epoch 3/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.1955 - categorical_accuracy: 0.9345 - val_loss: 0.1984 - val_categorical_accuracy: 0.9375\n",
      "Epoch 4/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.1656 - categorical_accuracy: 0.9420 - val_loss: 0.1700 - val_categorical_accuracy: 0.9417\n",
      "Epoch 5/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.1566 - categorical_accuracy: 0.9455 - val_loss: 0.1591 - val_categorical_accuracy: 0.9472\n",
      "Epoch 6/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.1421 - categorical_accuracy: 0.9491 - val_loss: 0.1511 - val_categorical_accuracy: 0.9479\n",
      "Epoch 7/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.1294 - categorical_accuracy: 0.9531 - val_loss: 0.1357 - val_categorical_accuracy: 0.9535\n",
      "Epoch 8/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.1237 - categorical_accuracy: 0.9549 - val_loss: 0.1363 - val_categorical_accuracy: 0.9521\n",
      "Epoch 9/100\n",
      "5760/5760 [==============================] - 101s 17ms/step - loss: 0.1214 - categorical_accuracy: 0.9568 - val_loss: 0.1196 - val_categorical_accuracy: 0.9583\n",
      "Epoch 10/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.1087 - categorical_accuracy: 0.9630 - val_loss: 0.1175 - val_categorical_accuracy: 0.9618\n",
      "Epoch 11/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0967 - categorical_accuracy: 0.9658 - val_loss: 0.1474 - val_categorical_accuracy: 0.9500\n",
      "Epoch 12/100\n",
      "5760/5760 [==============================] - 101s 17ms/step - loss: 0.0994 - categorical_accuracy: 0.9641 - val_loss: 0.1289 - val_categorical_accuracy: 0.9576\n",
      "Epoch 13/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0876 - categorical_accuracy: 0.9717 - val_loss: 0.1072 - val_categorical_accuracy: 0.9653\n",
      "Epoch 14/100\n",
      "5760/5760 [==============================] - 101s 17ms/step - loss: 0.0779 - categorical_accuracy: 0.9726 - val_loss: 0.1109 - val_categorical_accuracy: 0.9625\n",
      "Epoch 15/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0784 - categorical_accuracy: 0.9717 - val_loss: 0.1026 - val_categorical_accuracy: 0.9667\n",
      "Epoch 16/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0655 - categorical_accuracy: 0.9780 - val_loss: 0.1249 - val_categorical_accuracy: 0.9576\n",
      "Epoch 17/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0679 - categorical_accuracy: 0.9741 - val_loss: 0.1171 - val_categorical_accuracy: 0.9674\n",
      "Epoch 18/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0737 - categorical_accuracy: 0.9731 - val_loss: 0.1164 - val_categorical_accuracy: 0.9660\n",
      "Epoch 19/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0608 - categorical_accuracy: 0.9802 - val_loss: 0.1113 - val_categorical_accuracy: 0.9667\n",
      "Epoch 20/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0589 - categorical_accuracy: 0.9814 - val_loss: 0.1242 - val_categorical_accuracy: 0.9646\n",
      "Epoch 21/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0576 - categorical_accuracy: 0.9781 - val_loss: 0.1077 - val_categorical_accuracy: 0.9646\n",
      "Epoch 22/100\n",
      "5760/5760 [==============================] - 100s 17ms/step - loss: 0.0541 - categorical_accuracy: 0.9811 - val_loss: 0.1084 - val_categorical_accuracy: 0.9660\n",
      "Epoch 23/100\n",
      "5760/5760 [==============================] - 100s 17ms/step - loss: 0.0417 - categorical_accuracy: 0.9852 - val_loss: 0.1526 - val_categorical_accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0692 - categorical_accuracy: 0.9767 - val_loss: 0.1039 - val_categorical_accuracy: 0.9632\n",
      "Epoch 25/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0690 - categorical_accuracy: 0.9764 - val_loss: 0.1016 - val_categorical_accuracy: 0.9646\n",
      "Epoch 26/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0514 - categorical_accuracy: 0.9832 - val_loss: 0.1054 - val_categorical_accuracy: 0.9674\n",
      "Epoch 27/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0391 - categorical_accuracy: 0.9865 - val_loss: 0.1163 - val_categorical_accuracy: 0.9660\n",
      "Epoch 28/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0296 - categorical_accuracy: 0.9910 - val_loss: 0.1325 - val_categorical_accuracy: 0.9639\n",
      "Epoch 29/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0197 - categorical_accuracy: 0.9944 - val_loss: 0.1621 - val_categorical_accuracy: 0.9604\n",
      "Epoch 30/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0202 - categorical_accuracy: 0.9931 - val_loss: 0.1773 - val_categorical_accuracy: 0.9583\n",
      "Epoch 31/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0194 - categorical_accuracy: 0.9941 - val_loss: 0.1501 - val_categorical_accuracy: 0.9632\n",
      "Epoch 32/100\n",
      "5760/5760 [==============================] - 101s 17ms/step - loss: 0.0167 - categorical_accuracy: 0.9948 - val_loss: 0.1418 - val_categorical_accuracy: 0.9646\n",
      "Epoch 33/100\n",
      "5760/5760 [==============================] - 100s 17ms/step - loss: 0.0149 - categorical_accuracy: 0.9964 - val_loss: 0.1553 - val_categorical_accuracy: 0.9667\n",
      "Epoch 34/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0143 - categorical_accuracy: 0.9953 - val_loss: 0.1883 - val_categorical_accuracy: 0.9562\n",
      "Epoch 35/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0145 - categorical_accuracy: 0.9964 - val_loss: 0.1633 - val_categorical_accuracy: 0.9681\n",
      "Epoch 36/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0129 - categorical_accuracy: 0.9965 - val_loss: 0.1622 - val_categorical_accuracy: 0.9694\n",
      "Epoch 37/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0092 - categorical_accuracy: 0.9976 - val_loss: 0.1937 - val_categorical_accuracy: 0.9667\n",
      "Epoch 38/100\n",
      "5760/5760 [==============================] - 101s 17ms/step - loss: 0.0106 - categorical_accuracy: 0.9976 - val_loss: 0.1572 - val_categorical_accuracy: 0.9667\n",
      "Epoch 39/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0109 - categorical_accuracy: 0.9969 - val_loss: 0.1792 - val_categorical_accuracy: 0.9646\n",
      "Epoch 40/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0072 - categorical_accuracy: 0.9984 - val_loss: 0.1518 - val_categorical_accuracy: 0.9708\n",
      "Epoch 41/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0086 - categorical_accuracy: 0.9981 - val_loss: 0.1657 - val_categorical_accuracy: 0.9687\n",
      "Epoch 42/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0112 - categorical_accuracy: 0.9965 - val_loss: 0.1543 - val_categorical_accuracy: 0.9701\n",
      "Epoch 43/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0126 - categorical_accuracy: 0.9960 - val_loss: 0.1803 - val_categorical_accuracy: 0.9681\n",
      "Epoch 44/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0090 - categorical_accuracy: 0.9967 - val_loss: 0.2138 - val_categorical_accuracy: 0.9646\n",
      "Epoch 45/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0109 - categorical_accuracy: 0.9970 - val_loss: 0.1535 - val_categorical_accuracy: 0.9667\n",
      "Epoch 46/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0125 - categorical_accuracy: 0.9958 - val_loss: 0.1533 - val_categorical_accuracy: 0.9660\n",
      "Epoch 47/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0067 - categorical_accuracy: 0.9984 - val_loss: 0.1530 - val_categorical_accuracy: 0.9681\n",
      "Epoch 48/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0060 - categorical_accuracy: 0.9993 - val_loss: 0.1493 - val_categorical_accuracy: 0.9715\n",
      "Epoch 49/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0040 - categorical_accuracy: 0.9991 - val_loss: 0.1627 - val_categorical_accuracy: 0.9694\n",
      "Epoch 50/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0049 - categorical_accuracy: 0.9995 - val_loss: 0.1574 - val_categorical_accuracy: 0.9722\n",
      "Epoch 51/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0035 - categorical_accuracy: 0.9997 - val_loss: 0.1560 - val_categorical_accuracy: 0.9701\n",
      "Epoch 52/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0036 - categorical_accuracy: 0.9995 - val_loss: 0.1543 - val_categorical_accuracy: 0.9736\n",
      "Epoch 53/100\n",
      "5760/5760 [==============================] - 101s 17ms/step - loss: 0.0034 - categorical_accuracy: 0.9993 - val_loss: 0.1539 - val_categorical_accuracy: 0.9729\n",
      "Epoch 54/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0038 - categorical_accuracy: 0.9995 - val_loss: 0.1542 - val_categorical_accuracy: 0.9729\n",
      "Epoch 55/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0028 - categorical_accuracy: 0.9997 - val_loss: 0.1545 - val_categorical_accuracy: 0.9750\n",
      "Epoch 56/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0027 - categorical_accuracy: 0.9998 - val_loss: 0.1574 - val_categorical_accuracy: 0.9729\n",
      "Epoch 57/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0024 - categorical_accuracy: 0.9997 - val_loss: 0.1618 - val_categorical_accuracy: 0.9715\n",
      "Epoch 58/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 0.1625 - val_categorical_accuracy: 0.9701\n",
      "Epoch 59/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0024 - categorical_accuracy: 0.9998 - val_loss: 0.1612 - val_categorical_accuracy: 0.9729\n",
      "Epoch 60/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0020 - categorical_accuracy: 0.9998 - val_loss: 0.1639 - val_categorical_accuracy: 0.9736\n",
      "Epoch 61/100\n",
      "5760/5760 [==============================] - 102s 18ms/step - loss: 0.0020 - categorical_accuracy: 0.9998 - val_loss: 0.1653 - val_categorical_accuracy: 0.9722\n",
      "Epoch 62/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 0.1694 - val_categorical_accuracy: 0.9687\n",
      "Epoch 63/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0024 - categorical_accuracy: 0.9998 - val_loss: 0.1693 - val_categorical_accuracy: 0.9701\n",
      "Epoch 64/100\n",
      "5760/5760 [==============================] - 100s 17ms/step - loss: 0.0021 - categorical_accuracy: 0.9998 - val_loss: 0.1679 - val_categorical_accuracy: 0.9694\n",
      "Epoch 65/100\n",
      "5760/5760 [==============================] - 101s 18ms/step - loss: 0.0023 - categorical_accuracy: 0.9998 - val_loss: 0.1698 - val_categorical_accuracy: 0.9694\n",
      "\n",
      "Fold  1\n",
      "Train on 5760 samples, validate on 1440 samples\n",
      "Epoch 1/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.6139 - categorical_accuracy: 0.6003 - val_loss: 0.4944 - val_categorical_accuracy: 0.5646\n",
      "Epoch 2/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.4291 - categorical_accuracy: 0.8340 - val_loss: 0.3131 - val_categorical_accuracy: 0.9382\n",
      "Epoch 3/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.2513 - categorical_accuracy: 0.9182 - val_loss: 0.1623 - val_categorical_accuracy: 0.9451\n",
      "Epoch 4/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1925 - categorical_accuracy: 0.9349 - val_loss: 0.1753 - val_categorical_accuracy: 0.9410\n",
      "Epoch 5/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1727 - categorical_accuracy: 0.9415 - val_loss: 0.1497 - val_categorical_accuracy: 0.9493\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1513 - categorical_accuracy: 0.9470 - val_loss: 0.1652 - val_categorical_accuracy: 0.9403\n",
      "Epoch 7/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1433 - categorical_accuracy: 0.9521 - val_loss: 0.1439 - val_categorical_accuracy: 0.9521\n",
      "Epoch 8/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1375 - categorical_accuracy: 0.9531 - val_loss: 0.1434 - val_categorical_accuracy: 0.9458\n",
      "Epoch 9/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1187 - categorical_accuracy: 0.9575 - val_loss: 0.1253 - val_categorical_accuracy: 0.9535\n",
      "Epoch 10/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1142 - categorical_accuracy: 0.9613 - val_loss: 0.1219 - val_categorical_accuracy: 0.9556\n",
      "Epoch 11/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1102 - categorical_accuracy: 0.9606 - val_loss: 0.1330 - val_categorical_accuracy: 0.9514\n",
      "Epoch 12/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1024 - categorical_accuracy: 0.9635 - val_loss: 0.1101 - val_categorical_accuracy: 0.9583\n",
      "Epoch 13/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0959 - categorical_accuracy: 0.9667 - val_loss: 0.1284 - val_categorical_accuracy: 0.9549\n",
      "Epoch 14/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0961 - categorical_accuracy: 0.9674 - val_loss: 0.1083 - val_categorical_accuracy: 0.9625\n",
      "Epoch 15/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0885 - categorical_accuracy: 0.9684 - val_loss: 0.0992 - val_categorical_accuracy: 0.9632\n",
      "Epoch 16/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0895 - categorical_accuracy: 0.9686 - val_loss: 0.1001 - val_categorical_accuracy: 0.9590\n",
      "Epoch 17/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0750 - categorical_accuracy: 0.9752 - val_loss: 0.0938 - val_categorical_accuracy: 0.9708\n",
      "Epoch 18/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0751 - categorical_accuracy: 0.9759 - val_loss: 0.0958 - val_categorical_accuracy: 0.9681\n",
      "Epoch 19/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0748 - categorical_accuracy: 0.9747 - val_loss: 0.0959 - val_categorical_accuracy: 0.9667\n",
      "Epoch 20/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0716 - categorical_accuracy: 0.9762 - val_loss: 0.1190 - val_categorical_accuracy: 0.9632\n",
      "Epoch 21/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0838 - categorical_accuracy: 0.9705 - val_loss: 0.0991 - val_categorical_accuracy: 0.9694\n",
      "Epoch 22/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0687 - categorical_accuracy: 0.9753 - val_loss: 0.0897 - val_categorical_accuracy: 0.9694\n",
      "Epoch 23/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0665 - categorical_accuracy: 0.9771 - val_loss: 0.0917 - val_categorical_accuracy: 0.9694\n",
      "Epoch 24/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0652 - categorical_accuracy: 0.9776 - val_loss: 0.0955 - val_categorical_accuracy: 0.9694\n",
      "Epoch 25/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0647 - categorical_accuracy: 0.9764 - val_loss: 0.0956 - val_categorical_accuracy: 0.9708\n",
      "Epoch 26/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0584 - categorical_accuracy: 0.9804 - val_loss: 0.0903 - val_categorical_accuracy: 0.9708\n",
      "Epoch 27/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0506 - categorical_accuracy: 0.9826 - val_loss: 0.0992 - val_categorical_accuracy: 0.9688\n",
      "Epoch 28/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0500 - categorical_accuracy: 0.9845 - val_loss: 0.1018 - val_categorical_accuracy: 0.9701\n",
      "Epoch 29/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0537 - categorical_accuracy: 0.9819 - val_loss: 0.0998 - val_categorical_accuracy: 0.9687\n",
      "Epoch 30/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0477 - categorical_accuracy: 0.9833 - val_loss: 0.0992 - val_categorical_accuracy: 0.9687\n",
      "Epoch 31/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0416 - categorical_accuracy: 0.9854 - val_loss: 0.1027 - val_categorical_accuracy: 0.9708\n",
      "Epoch 32/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0377 - categorical_accuracy: 0.9875 - val_loss: 0.1308 - val_categorical_accuracy: 0.9618\n",
      "Epoch 33/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0404 - categorical_accuracy: 0.9856 - val_loss: 0.1170 - val_categorical_accuracy: 0.9708\n",
      "Epoch 34/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0311 - categorical_accuracy: 0.9906 - val_loss: 0.1108 - val_categorical_accuracy: 0.9674\n",
      "Epoch 35/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0353 - categorical_accuracy: 0.9899 - val_loss: 0.1305 - val_categorical_accuracy: 0.9701\n",
      "Epoch 36/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0415 - categorical_accuracy: 0.9858 - val_loss: 0.1206 - val_categorical_accuracy: 0.9687\n",
      "Epoch 37/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0305 - categorical_accuracy: 0.9906 - val_loss: 0.1247 - val_categorical_accuracy: 0.9687\n",
      "Epoch 38/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0287 - categorical_accuracy: 0.9906 - val_loss: 0.2065 - val_categorical_accuracy: 0.9465\n",
      "Epoch 39/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0409 - categorical_accuracy: 0.9861 - val_loss: 0.1304 - val_categorical_accuracy: 0.9653\n",
      "Epoch 40/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0351 - categorical_accuracy: 0.9880 - val_loss: 0.1497 - val_categorical_accuracy: 0.9625\n",
      "Epoch 41/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0314 - categorical_accuracy: 0.9896 - val_loss: 0.1132 - val_categorical_accuracy: 0.9708\n",
      "Epoch 42/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0226 - categorical_accuracy: 0.9927 - val_loss: 0.1284 - val_categorical_accuracy: 0.9681\n",
      "Epoch 43/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0182 - categorical_accuracy: 0.9948 - val_loss: 0.1547 - val_categorical_accuracy: 0.9639\n",
      "Epoch 44/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0220 - categorical_accuracy: 0.9938 - val_loss: 0.1498 - val_categorical_accuracy: 0.9653\n",
      "Epoch 45/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0188 - categorical_accuracy: 0.9934 - val_loss: 0.1410 - val_categorical_accuracy: 0.9674\n",
      "Epoch 46/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0146 - categorical_accuracy: 0.9955 - val_loss: 0.1715 - val_categorical_accuracy: 0.9625\n",
      "Epoch 47/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0118 - categorical_accuracy: 0.9964 - val_loss: 0.1590 - val_categorical_accuracy: 0.9653\n",
      "Epoch 48/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0080 - categorical_accuracy: 0.9983 - val_loss: 0.1635 - val_categorical_accuracy: 0.9667\n",
      "Epoch 49/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0074 - categorical_accuracy: 0.9984 - val_loss: 0.1775 - val_categorical_accuracy: 0.9639\n",
      "Epoch 50/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0058 - categorical_accuracy: 0.9986 - val_loss: 0.2203 - val_categorical_accuracy: 0.9625\n",
      "Epoch 51/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0193 - categorical_accuracy: 0.9936 - val_loss: 0.2060 - val_categorical_accuracy: 0.9500\n",
      "Epoch 52/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0319 - categorical_accuracy: 0.9889 - val_loss: 0.1532 - val_categorical_accuracy: 0.9639\n",
      "Epoch 53/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0170 - categorical_accuracy: 0.9934 - val_loss: 0.1708 - val_categorical_accuracy: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0114 - categorical_accuracy: 0.9965 - val_loss: 0.1666 - val_categorical_accuracy: 0.9660\n",
      "Epoch 55/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0050 - categorical_accuracy: 0.9986 - val_loss: 0.2018 - val_categorical_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0042 - categorical_accuracy: 0.9983 - val_loss: 0.1825 - val_categorical_accuracy: 0.9660\n",
      "Epoch 57/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0015 - categorical_accuracy: 0.9998 - val_loss: 0.1956 - val_categorical_accuracy: 0.9618\n",
      "Epoch 58/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 0.2074 - val_categorical_accuracy: 0.9632\n",
      "Epoch 59/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 9.2624e-04 - categorical_accuracy: 0.9998 - val_loss: 0.2240 - val_categorical_accuracy: 0.9632\n",
      "Epoch 60/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 7.4776e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2282 - val_categorical_accuracy: 0.9597\n",
      "Epoch 61/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 5.6199e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2335 - val_categorical_accuracy: 0.9597\n",
      "Epoch 62/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0103 - categorical_accuracy: 0.9969 - val_loss: 0.2799 - val_categorical_accuracy: 0.9458\n",
      "Epoch 63/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0187 - categorical_accuracy: 0.9943 - val_loss: 0.1944 - val_categorical_accuracy: 0.9618\n",
      "Epoch 64/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0120 - categorical_accuracy: 0.9955 - val_loss: 0.1894 - val_categorical_accuracy: 0.9667\n",
      "Epoch 65/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0064 - categorical_accuracy: 0.9977 - val_loss: 0.2295 - val_categorical_accuracy: 0.9590\n",
      "Epoch 66/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0026 - categorical_accuracy: 0.9997 - val_loss: 0.2222 - val_categorical_accuracy: 0.9632\n",
      "Epoch 67/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0018 - categorical_accuracy: 0.9997 - val_loss: 0.2318 - val_categorical_accuracy: 0.9604\n",
      "\n",
      "Fold  2\n",
      "Train on 5760 samples, validate on 1440 samples\n",
      "Epoch 1/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.6283 - categorical_accuracy: 0.6340 - val_loss: 0.5038 - val_categorical_accuracy: 0.5903\n",
      "Epoch 2/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.4563 - categorical_accuracy: 0.7785 - val_loss: 0.3660 - val_categorical_accuracy: 0.8840\n",
      "Epoch 3/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.3025 - categorical_accuracy: 0.9109 - val_loss: 0.1936 - val_categorical_accuracy: 0.9431\n",
      "Epoch 4/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.2033 - categorical_accuracy: 0.9293 - val_loss: 0.1556 - val_categorical_accuracy: 0.9479\n",
      "Epoch 5/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1850 - categorical_accuracy: 0.9361 - val_loss: 0.1571 - val_categorical_accuracy: 0.9451\n",
      "Epoch 6/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1738 - categorical_accuracy: 0.9387 - val_loss: 0.1394 - val_categorical_accuracy: 0.9521\n",
      "Epoch 7/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.1638 - categorical_accuracy: 0.9422 - val_loss: 0.1316 - val_categorical_accuracy: 0.9514\n",
      "Epoch 8/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1577 - categorical_accuracy: 0.9453 - val_loss: 0.1498 - val_categorical_accuracy: 0.9437\n",
      "Epoch 9/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1476 - categorical_accuracy: 0.9497 - val_loss: 0.1192 - val_categorical_accuracy: 0.9514\n",
      "Epoch 10/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.1448 - categorical_accuracy: 0.9503 - val_loss: 0.1105 - val_categorical_accuracy: 0.9542\n",
      "Epoch 11/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1253 - categorical_accuracy: 0.9561 - val_loss: 0.1056 - val_categorical_accuracy: 0.9576\n",
      "Epoch 12/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1249 - categorical_accuracy: 0.9547 - val_loss: 0.1349 - val_categorical_accuracy: 0.9486\n",
      "Epoch 13/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1285 - categorical_accuracy: 0.9573 - val_loss: 0.1261 - val_categorical_accuracy: 0.9493\n",
      "Epoch 14/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1213 - categorical_accuracy: 0.9571 - val_loss: 0.0980 - val_categorical_accuracy: 0.9597\n",
      "Epoch 15/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1097 - categorical_accuracy: 0.9616 - val_loss: 0.1004 - val_categorical_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1066 - categorical_accuracy: 0.9637 - val_loss: 0.0937 - val_categorical_accuracy: 0.9646\n",
      "Epoch 17/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1073 - categorical_accuracy: 0.9622 - val_loss: 0.0870 - val_categorical_accuracy: 0.9681\n",
      "Epoch 18/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1000 - categorical_accuracy: 0.9649 - val_loss: 0.0818 - val_categorical_accuracy: 0.9694\n",
      "Epoch 19/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0981 - categorical_accuracy: 0.9674 - val_loss: 0.0859 - val_categorical_accuracy: 0.9646\n",
      "Epoch 20/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0917 - categorical_accuracy: 0.9675 - val_loss: 0.0805 - val_categorical_accuracy: 0.9701\n",
      "Epoch 21/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0881 - categorical_accuracy: 0.9693 - val_loss: 0.0786 - val_categorical_accuracy: 0.9722\n",
      "Epoch 22/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0871 - categorical_accuracy: 0.9703 - val_loss: 0.0833 - val_categorical_accuracy: 0.9653\n",
      "Epoch 23/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0880 - categorical_accuracy: 0.9705 - val_loss: 0.0800 - val_categorical_accuracy: 0.9736\n",
      "Epoch 24/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0818 - categorical_accuracy: 0.9726 - val_loss: 0.1100 - val_categorical_accuracy: 0.9556\n",
      "Epoch 25/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0808 - categorical_accuracy: 0.9724 - val_loss: 0.0785 - val_categorical_accuracy: 0.9694\n",
      "Epoch 26/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0807 - categorical_accuracy: 0.9727 - val_loss: 0.0770 - val_categorical_accuracy: 0.9750\n",
      "Epoch 27/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0630 - categorical_accuracy: 0.9795 - val_loss: 0.0795 - val_categorical_accuracy: 0.9743\n",
      "Epoch 28/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0612 - categorical_accuracy: 0.9800 - val_loss: 0.0773 - val_categorical_accuracy: 0.9688\n",
      "Epoch 29/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0604 - categorical_accuracy: 0.9776 - val_loss: 0.1674 - val_categorical_accuracy: 0.9618\n",
      "Epoch 30/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1526 - categorical_accuracy: 0.9493 - val_loss: 0.0904 - val_categorical_accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0945 - categorical_accuracy: 0.9701 - val_loss: 0.0823 - val_categorical_accuracy: 0.9701\n",
      "Epoch 32/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0807 - categorical_accuracy: 0.9727 - val_loss: 0.0805 - val_categorical_accuracy: 0.9694\n",
      "Epoch 33/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0651 - categorical_accuracy: 0.9795 - val_loss: 0.0754 - val_categorical_accuracy: 0.9687\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0646 - categorical_accuracy: 0.9792 - val_loss: 0.0953 - val_categorical_accuracy: 0.9646\n",
      "Epoch 35/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0593 - categorical_accuracy: 0.9816 - val_loss: 0.0849 - val_categorical_accuracy: 0.9660\n",
      "Epoch 36/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0560 - categorical_accuracy: 0.9828 - val_loss: 0.0822 - val_categorical_accuracy: 0.9681\n",
      "Epoch 37/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0506 - categorical_accuracy: 0.9828 - val_loss: 0.0909 - val_categorical_accuracy: 0.9653\n",
      "Epoch 38/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0509 - categorical_accuracy: 0.9826 - val_loss: 0.0873 - val_categorical_accuracy: 0.9667\n",
      "Epoch 39/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0423 - categorical_accuracy: 0.9877 - val_loss: 0.0935 - val_categorical_accuracy: 0.9736\n",
      "Epoch 40/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0479 - categorical_accuracy: 0.9832 - val_loss: 0.0965 - val_categorical_accuracy: 0.9708\n",
      "Epoch 41/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0359 - categorical_accuracy: 0.9889 - val_loss: 0.0995 - val_categorical_accuracy: 0.9722\n",
      "Epoch 42/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0374 - categorical_accuracy: 0.9901 - val_loss: 0.1032 - val_categorical_accuracy: 0.9660\n",
      "Epoch 43/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0352 - categorical_accuracy: 0.9903 - val_loss: 0.0994 - val_categorical_accuracy: 0.9708\n",
      "Epoch 44/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0288 - categorical_accuracy: 0.9931 - val_loss: 0.1141 - val_categorical_accuracy: 0.9701\n",
      "Epoch 45/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0265 - categorical_accuracy: 0.9929 - val_loss: 0.1398 - val_categorical_accuracy: 0.9604\n",
      "Epoch 46/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0302 - categorical_accuracy: 0.9899 - val_loss: 0.1162 - val_categorical_accuracy: 0.9701\n",
      "Epoch 47/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0288 - categorical_accuracy: 0.9915 - val_loss: 0.1137 - val_categorical_accuracy: 0.9694\n",
      "Epoch 48/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0290 - categorical_accuracy: 0.9920 - val_loss: 0.1370 - val_categorical_accuracy: 0.9660\n",
      "Epoch 49/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0241 - categorical_accuracy: 0.9924 - val_loss: 0.1147 - val_categorical_accuracy: 0.9694\n",
      "Epoch 50/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0340 - categorical_accuracy: 0.9885 - val_loss: 0.1087 - val_categorical_accuracy: 0.9722\n",
      "Epoch 51/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0287 - categorical_accuracy: 0.9896 - val_loss: 0.1110 - val_categorical_accuracy: 0.9694\n",
      "Epoch 52/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0255 - categorical_accuracy: 0.9925 - val_loss: 0.1196 - val_categorical_accuracy: 0.9708\n",
      "Epoch 53/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0171 - categorical_accuracy: 0.9957 - val_loss: 0.1159 - val_categorical_accuracy: 0.9688\n",
      "Epoch 54/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0151 - categorical_accuracy: 0.9970 - val_loss: 0.1417 - val_categorical_accuracy: 0.9660\n",
      "Epoch 55/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0148 - categorical_accuracy: 0.9967 - val_loss: 0.1232 - val_categorical_accuracy: 0.9694\n",
      "Epoch 56/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0126 - categorical_accuracy: 0.9977 - val_loss: 0.1241 - val_categorical_accuracy: 0.9729\n",
      "Epoch 57/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0096 - categorical_accuracy: 0.9979 - val_loss: 0.1298 - val_categorical_accuracy: 0.9688\n",
      "Epoch 58/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0113 - categorical_accuracy: 0.9974 - val_loss: 0.1265 - val_categorical_accuracy: 0.9715\n",
      "Epoch 59/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0101 - categorical_accuracy: 0.9979 - val_loss: 0.1355 - val_categorical_accuracy: 0.9688\n",
      "Epoch 60/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0109 - categorical_accuracy: 0.9972 - val_loss: 0.1652 - val_categorical_accuracy: 0.9660\n",
      "Epoch 61/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0155 - categorical_accuracy: 0.9957 - val_loss: 0.1532 - val_categorical_accuracy: 0.9681\n",
      "Epoch 62/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0130 - categorical_accuracy: 0.9965 - val_loss: 0.1375 - val_categorical_accuracy: 0.9736\n",
      "Epoch 63/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0247 - categorical_accuracy: 0.9920 - val_loss: 0.1439 - val_categorical_accuracy: 0.9674\n",
      "Epoch 64/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0140 - categorical_accuracy: 0.9964 - val_loss: 0.1402 - val_categorical_accuracy: 0.9694\n",
      "Epoch 65/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0094 - categorical_accuracy: 0.9981 - val_loss: 0.1443 - val_categorical_accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0092 - categorical_accuracy: 0.9983 - val_loss: 0.1521 - val_categorical_accuracy: 0.9674\n",
      "Epoch 67/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0082 - categorical_accuracy: 0.9981 - val_loss: 0.1393 - val_categorical_accuracy: 0.9708\n",
      "Epoch 68/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0076 - categorical_accuracy: 0.9983 - val_loss: 0.1532 - val_categorical_accuracy: 0.9701\n",
      "Epoch 69/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0073 - categorical_accuracy: 0.9988 - val_loss: 0.1552 - val_categorical_accuracy: 0.9694\n",
      "Epoch 70/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0061 - categorical_accuracy: 0.9986 - val_loss: 0.1534 - val_categorical_accuracy: 0.9694\n",
      "Epoch 71/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0063 - categorical_accuracy: 0.9990 - val_loss: 0.1645 - val_categorical_accuracy: 0.9681\n",
      "Epoch 72/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0071 - categorical_accuracy: 0.9988 - val_loss: 0.1644 - val_categorical_accuracy: 0.9688\n",
      "Epoch 73/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0066 - categorical_accuracy: 0.9988 - val_loss: 0.1623 - val_categorical_accuracy: 0.9701\n",
      "Epoch 74/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0055 - categorical_accuracy: 0.9988 - val_loss: 0.1655 - val_categorical_accuracy: 0.9701\n",
      "Epoch 75/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0052 - categorical_accuracy: 0.9988 - val_loss: 0.1689 - val_categorical_accuracy: 0.9701\n",
      "Epoch 76/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0046 - categorical_accuracy: 0.9991 - val_loss: 0.1693 - val_categorical_accuracy: 0.9708\n",
      "Epoch 77/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0049 - categorical_accuracy: 0.9993 - val_loss: 0.1677 - val_categorical_accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0046 - categorical_accuracy: 0.9991 - val_loss: 0.1728 - val_categorical_accuracy: 0.9646\n",
      "Epoch 79/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0041 - categorical_accuracy: 0.9991 - val_loss: 0.1790 - val_categorical_accuracy: 0.9688\n",
      "Epoch 81/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0035 - categorical_accuracy: 0.9997 - val_loss: 0.1962 - val_categorical_accuracy: 0.9681\n",
      "Epoch 82/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0046 - categorical_accuracy: 0.9991 - val_loss: 0.1643 - val_categorical_accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0033 - categorical_accuracy: 0.9995 - val_loss: 0.1792 - val_categorical_accuracy: 0.9715\n",
      "Epoch 84/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0029 - categorical_accuracy: 0.9995 - val_loss: 0.1903 - val_categorical_accuracy: 0.9701\n",
      "Epoch 85/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0034 - categorical_accuracy: 0.9993 - val_loss: 0.1898 - val_categorical_accuracy: 0.9708\n",
      "Epoch 86/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0282 - categorical_accuracy: 0.9927 - val_loss: 0.6589 - val_categorical_accuracy: 0.9007\n",
      "Epoch 87/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.2239 - categorical_accuracy: 0.9491 - val_loss: 0.1618 - val_categorical_accuracy: 0.9542\n",
      "Epoch 88/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0804 - categorical_accuracy: 0.9773 - val_loss: 0.0901 - val_categorical_accuracy: 0.9715\n",
      "Epoch 89/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0389 - categorical_accuracy: 0.9885 - val_loss: 0.0876 - val_categorical_accuracy: 0.9736\n",
      "Epoch 90/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0188 - categorical_accuracy: 0.9957 - val_loss: 0.0925 - val_categorical_accuracy: 0.9736\n",
      "Epoch 91/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0103 - categorical_accuracy: 0.9979 - val_loss: 0.1028 - val_categorical_accuracy: 0.9771\n",
      "\n",
      "Fold  3\n",
      "Train on 5760 samples, validate on 1440 samples\n",
      "Epoch 1/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.6358 - categorical_accuracy: 0.6818 - val_loss: 0.5201 - val_categorical_accuracy: 0.7806\n",
      "Epoch 2/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.4668 - categorical_accuracy: 0.7653 - val_loss: 0.3778 - val_categorical_accuracy: 0.9431\n",
      "Epoch 3/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.3257 - categorical_accuracy: 0.9040 - val_loss: 0.1904 - val_categorical_accuracy: 0.9465\n",
      "Epoch 4/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.2210 - categorical_accuracy: 0.9231 - val_loss: 0.1594 - val_categorical_accuracy: 0.9382\n",
      "Epoch 5/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1922 - categorical_accuracy: 0.9293 - val_loss: 0.1896 - val_categorical_accuracy: 0.9285\n",
      "Epoch 6/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.2008 - categorical_accuracy: 0.9253 - val_loss: 0.1291 - val_categorical_accuracy: 0.9549\n",
      "Epoch 7/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1792 - categorical_accuracy: 0.9328 - val_loss: 0.1215 - val_categorical_accuracy: 0.9583\n",
      "Epoch 8/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1543 - categorical_accuracy: 0.9453 - val_loss: 0.1116 - val_categorical_accuracy: 0.9569\n",
      "Epoch 9/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1452 - categorical_accuracy: 0.9498 - val_loss: 0.1139 - val_categorical_accuracy: 0.9569\n",
      "Epoch 10/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1370 - categorical_accuracy: 0.9517 - val_loss: 0.1065 - val_categorical_accuracy: 0.9618\n",
      "Epoch 11/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1202 - categorical_accuracy: 0.9568 - val_loss: 0.0977 - val_categorical_accuracy: 0.9639\n",
      "Epoch 12/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1155 - categorical_accuracy: 0.9575 - val_loss: 0.0970 - val_categorical_accuracy: 0.9632\n",
      "Epoch 13/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1227 - categorical_accuracy: 0.9562 - val_loss: 0.0979 - val_categorical_accuracy: 0.9646\n",
      "Epoch 14/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1021 - categorical_accuracy: 0.9660 - val_loss: 0.0790 - val_categorical_accuracy: 0.9729\n",
      "Epoch 15/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1010 - categorical_accuracy: 0.9658 - val_loss: 0.0741 - val_categorical_accuracy: 0.9764\n",
      "Epoch 16/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1019 - categorical_accuracy: 0.9646 - val_loss: 0.0755 - val_categorical_accuracy: 0.9729\n",
      "Epoch 17/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1390 - categorical_accuracy: 0.9516 - val_loss: 0.1274 - val_categorical_accuracy: 0.9528\n",
      "Epoch 18/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1115 - categorical_accuracy: 0.9609 - val_loss: 0.1133 - val_categorical_accuracy: 0.9576\n",
      "Epoch 19/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1213 - categorical_accuracy: 0.9557 - val_loss: 0.0981 - val_categorical_accuracy: 0.9611\n",
      "Epoch 20/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0981 - categorical_accuracy: 0.9674 - val_loss: 0.0711 - val_categorical_accuracy: 0.9743\n",
      "Epoch 21/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0819 - categorical_accuracy: 0.9703 - val_loss: 0.0646 - val_categorical_accuracy: 0.9792\n",
      "Epoch 22/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0944 - categorical_accuracy: 0.9684 - val_loss: 0.0641 - val_categorical_accuracy: 0.9785\n",
      "Epoch 23/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0782 - categorical_accuracy: 0.9726 - val_loss: 0.0835 - val_categorical_accuracy: 0.9674\n",
      "Epoch 24/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0769 - categorical_accuracy: 0.9750 - val_loss: 0.0727 - val_categorical_accuracy: 0.9729\n",
      "Epoch 25/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0769 - categorical_accuracy: 0.9729 - val_loss: 0.0876 - val_categorical_accuracy: 0.9708\n",
      "Epoch 26/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0807 - categorical_accuracy: 0.9710 - val_loss: 0.0828 - val_categorical_accuracy: 0.9681\n",
      "Epoch 27/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0857 - categorical_accuracy: 0.9714 - val_loss: 0.0636 - val_categorical_accuracy: 0.9771\n",
      "Epoch 28/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0741 - categorical_accuracy: 0.9764 - val_loss: 0.0624 - val_categorical_accuracy: 0.9799\n",
      "Epoch 29/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0751 - categorical_accuracy: 0.9736 - val_loss: 0.0645 - val_categorical_accuracy: 0.9771\n",
      "Epoch 30/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0672 - categorical_accuracy: 0.9778 - val_loss: 0.0609 - val_categorical_accuracy: 0.9799\n",
      "Epoch 31/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0606 - categorical_accuracy: 0.9813 - val_loss: 0.0826 - val_categorical_accuracy: 0.9729\n",
      "Epoch 32/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0692 - categorical_accuracy: 0.9759 - val_loss: 0.0742 - val_categorical_accuracy: 0.9729\n",
      "Epoch 33/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0666 - categorical_accuracy: 0.9786 - val_loss: 0.0624 - val_categorical_accuracy: 0.9792\n",
      "Epoch 34/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0553 - categorical_accuracy: 0.9826 - val_loss: 0.0869 - val_categorical_accuracy: 0.9715\n",
      "Epoch 35/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0730 - categorical_accuracy: 0.9760 - val_loss: 0.1192 - val_categorical_accuracy: 0.9590\n",
      "Epoch 36/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0756 - categorical_accuracy: 0.9753 - val_loss: 0.0708 - val_categorical_accuracy: 0.9736\n",
      "Epoch 37/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0556 - categorical_accuracy: 0.9816 - val_loss: 0.0708 - val_categorical_accuracy: 0.9757\n",
      "Epoch 38/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0478 - categorical_accuracy: 0.9861 - val_loss: 0.0689 - val_categorical_accuracy: 0.9757\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0517 - categorical_accuracy: 0.9845 - val_loss: 0.0717 - val_categorical_accuracy: 0.9785\n",
      "Epoch 40/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0437 - categorical_accuracy: 0.9865 - val_loss: 0.0721 - val_categorical_accuracy: 0.9743\n",
      "Epoch 41/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0364 - categorical_accuracy: 0.9894 - val_loss: 0.0801 - val_categorical_accuracy: 0.9771\n",
      "Epoch 42/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0353 - categorical_accuracy: 0.9917 - val_loss: 0.0816 - val_categorical_accuracy: 0.9736\n",
      "Epoch 43/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0307 - categorical_accuracy: 0.9936 - val_loss: 0.0763 - val_categorical_accuracy: 0.9764\n",
      "Epoch 44/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0282 - categorical_accuracy: 0.9911 - val_loss: 0.0783 - val_categorical_accuracy: 0.9743\n",
      "Epoch 45/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0265 - categorical_accuracy: 0.9938 - val_loss: 0.0817 - val_categorical_accuracy: 0.9743\n",
      "Epoch 46/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0213 - categorical_accuracy: 0.9951 - val_loss: 0.0852 - val_categorical_accuracy: 0.9764\n",
      "Epoch 47/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0236 - categorical_accuracy: 0.9939 - val_loss: 0.1043 - val_categorical_accuracy: 0.9708\n",
      "Epoch 48/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0379 - categorical_accuracy: 0.9873 - val_loss: 0.0824 - val_categorical_accuracy: 0.9701\n",
      "Epoch 49/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0376 - categorical_accuracy: 0.9892 - val_loss: 0.0821 - val_categorical_accuracy: 0.9715\n",
      "Epoch 50/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0218 - categorical_accuracy: 0.9944 - val_loss: 0.0861 - val_categorical_accuracy: 0.9729\n",
      "Epoch 51/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0154 - categorical_accuracy: 0.9965 - val_loss: 0.1087 - val_categorical_accuracy: 0.9729\n",
      "Epoch 52/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0121 - categorical_accuracy: 0.9970 - val_loss: 0.0932 - val_categorical_accuracy: 0.9722\n",
      "Epoch 53/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0165 - categorical_accuracy: 0.9955 - val_loss: 0.1746 - val_categorical_accuracy: 0.9590\n",
      "Epoch 54/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0406 - categorical_accuracy: 0.9854 - val_loss: 0.0686 - val_categorical_accuracy: 0.9764\n",
      "Epoch 55/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0346 - categorical_accuracy: 0.9898 - val_loss: 0.0684 - val_categorical_accuracy: 0.9757\n",
      "Epoch 56/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0166 - categorical_accuracy: 0.9965 - val_loss: 0.0731 - val_categorical_accuracy: 0.9792\n",
      "Epoch 57/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0119 - categorical_accuracy: 0.9977 - val_loss: 0.0998 - val_categorical_accuracy: 0.9708\n",
      "Epoch 58/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0107 - categorical_accuracy: 0.9979 - val_loss: 0.1117 - val_categorical_accuracy: 0.9715\n",
      "Epoch 59/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0106 - categorical_accuracy: 0.9972 - val_loss: 0.1296 - val_categorical_accuracy: 0.9743\n",
      "Epoch 60/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0152 - categorical_accuracy: 0.9962 - val_loss: 0.0888 - val_categorical_accuracy: 0.9785\n",
      "Epoch 61/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0156 - categorical_accuracy: 0.9955 - val_loss: 0.1349 - val_categorical_accuracy: 0.9681\n",
      "Epoch 62/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0179 - categorical_accuracy: 0.9958 - val_loss: 0.1054 - val_categorical_accuracy: 0.9708\n",
      "Epoch 63/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0161 - categorical_accuracy: 0.9958 - val_loss: 0.1086 - val_categorical_accuracy: 0.9715\n",
      "Epoch 64/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0118 - categorical_accuracy: 0.9969 - val_loss: 0.0889 - val_categorical_accuracy: 0.9743\n",
      "Epoch 65/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0039 - categorical_accuracy: 0.9993 - val_loss: 0.1220 - val_categorical_accuracy: 0.9736\n",
      "Epoch 66/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0066 - categorical_accuracy: 0.9981 - val_loss: 0.1182 - val_categorical_accuracy: 0.9764\n",
      "Epoch 67/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0048 - categorical_accuracy: 0.9988 - val_loss: 0.1375 - val_categorical_accuracy: 0.9708\n",
      "Epoch 68/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0052 - categorical_accuracy: 0.9988 - val_loss: 0.1328 - val_categorical_accuracy: 0.9722\n",
      "Epoch 69/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0036 - categorical_accuracy: 0.9991 - val_loss: 0.1233 - val_categorical_accuracy: 0.9736\n",
      "Epoch 70/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0026 - categorical_accuracy: 0.9997 - val_loss: 0.1268 - val_categorical_accuracy: 0.9771\n",
      "Epoch 71/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0021 - categorical_accuracy: 0.9998 - val_loss: 0.1319 - val_categorical_accuracy: 0.9757\n",
      "Epoch 72/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 0.1397 - val_categorical_accuracy: 0.9750\n",
      "Epoch 73/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 0.1466 - val_categorical_accuracy: 0.9764\n",
      "Epoch 74/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0021 - categorical_accuracy: 0.9998 - val_loss: 0.1546 - val_categorical_accuracy: 0.9736\n",
      "Epoch 75/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0020 - categorical_accuracy: 0.9998 - val_loss: 0.1579 - val_categorical_accuracy: 0.9736\n",
      "Epoch 76/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0018 - categorical_accuracy: 0.9998 - val_loss: 0.1609 - val_categorical_accuracy: 0.9750\n",
      "Epoch 77/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 0.1648 - val_categorical_accuracy: 0.9736\n",
      "Epoch 78/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0020 - categorical_accuracy: 0.9998 - val_loss: 0.1695 - val_categorical_accuracy: 0.9750\n",
      "Epoch 79/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0021 - categorical_accuracy: 0.9998 - val_loss: 0.1729 - val_categorical_accuracy: 0.9743\n",
      "Epoch 80/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 0.1758 - val_categorical_accuracy: 0.9743\n",
      "\n",
      "Fold  4\n",
      "Train on 5760 samples, validate on 1440 samples\n",
      "Epoch 1/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.6360 - categorical_accuracy: 0.6163 - val_loss: 0.5228 - val_categorical_accuracy: 0.6479\n",
      "Epoch 2/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.4754 - categorical_accuracy: 0.7465 - val_loss: 0.3859 - val_categorical_accuracy: 0.9174\n",
      "Epoch 3/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.3239 - categorical_accuracy: 0.9104 - val_loss: 0.2005 - val_categorical_accuracy: 0.9451\n",
      "Epoch 4/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.2219 - categorical_accuracy: 0.9198 - val_loss: 0.1925 - val_categorical_accuracy: 0.9368\n",
      "Epoch 5/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.2281 - categorical_accuracy: 0.9160 - val_loss: 0.1532 - val_categorical_accuracy: 0.9465\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1822 - categorical_accuracy: 0.9359 - val_loss: 0.1397 - val_categorical_accuracy: 0.9507\n",
      "Epoch 7/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1691 - categorical_accuracy: 0.9427 - val_loss: 0.1344 - val_categorical_accuracy: 0.9542\n",
      "Epoch 8/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1613 - categorical_accuracy: 0.9437 - val_loss: 0.1302 - val_categorical_accuracy: 0.9549\n",
      "Epoch 9/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1567 - categorical_accuracy: 0.9472 - val_loss: 0.1263 - val_categorical_accuracy: 0.9563\n",
      "Epoch 10/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1557 - categorical_accuracy: 0.9469 - val_loss: 0.1151 - val_categorical_accuracy: 0.9583\n",
      "Epoch 11/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1500 - categorical_accuracy: 0.9490 - val_loss: 0.1475 - val_categorical_accuracy: 0.9528\n",
      "Epoch 12/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1567 - categorical_accuracy: 0.9486 - val_loss: 0.1075 - val_categorical_accuracy: 0.9660\n",
      "Epoch 13/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1304 - categorical_accuracy: 0.9538 - val_loss: 0.1059 - val_categorical_accuracy: 0.9646\n",
      "Epoch 14/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.1267 - categorical_accuracy: 0.9547 - val_loss: 0.0975 - val_categorical_accuracy: 0.9701\n",
      "Epoch 15/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1225 - categorical_accuracy: 0.9604 - val_loss: 0.1103 - val_categorical_accuracy: 0.9604\n",
      "Epoch 16/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1175 - categorical_accuracy: 0.9627 - val_loss: 0.0932 - val_categorical_accuracy: 0.9715\n",
      "Epoch 17/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1054 - categorical_accuracy: 0.9661 - val_loss: 0.0892 - val_categorical_accuracy: 0.9687\n",
      "Epoch 18/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1178 - categorical_accuracy: 0.9616 - val_loss: 0.1025 - val_categorical_accuracy: 0.9625\n",
      "Epoch 19/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.1026 - categorical_accuracy: 0.9646 - val_loss: 0.0991 - val_categorical_accuracy: 0.9687\n",
      "Epoch 20/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.1009 - categorical_accuracy: 0.9658 - val_loss: 0.0858 - val_categorical_accuracy: 0.9681\n",
      "Epoch 21/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0977 - categorical_accuracy: 0.9658 - val_loss: 0.0931 - val_categorical_accuracy: 0.9625\n",
      "Epoch 22/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.1018 - categorical_accuracy: 0.9651 - val_loss: 0.0995 - val_categorical_accuracy: 0.9625\n",
      "Epoch 23/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0984 - categorical_accuracy: 0.9658 - val_loss: 0.0902 - val_categorical_accuracy: 0.9708\n",
      "Epoch 24/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0946 - categorical_accuracy: 0.9679 - val_loss: 0.0811 - val_categorical_accuracy: 0.9708\n",
      "Epoch 25/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0884 - categorical_accuracy: 0.9710 - val_loss: 0.0807 - val_categorical_accuracy: 0.9729\n",
      "Epoch 26/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0834 - categorical_accuracy: 0.9719 - val_loss: 0.0798 - val_categorical_accuracy: 0.9764\n",
      "Epoch 27/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0871 - categorical_accuracy: 0.9707 - val_loss: 0.0919 - val_categorical_accuracy: 0.9674\n",
      "Epoch 28/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0817 - categorical_accuracy: 0.9736 - val_loss: 0.0872 - val_categorical_accuracy: 0.9701\n",
      "Epoch 29/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0833 - categorical_accuracy: 0.9707 - val_loss: 0.0749 - val_categorical_accuracy: 0.9750\n",
      "Epoch 30/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0738 - categorical_accuracy: 0.9769 - val_loss: 0.0732 - val_categorical_accuracy: 0.9743\n",
      "Epoch 31/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0787 - categorical_accuracy: 0.9759 - val_loss: 0.0860 - val_categorical_accuracy: 0.9715\n",
      "Epoch 32/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0676 - categorical_accuracy: 0.9778 - val_loss: 0.0806 - val_categorical_accuracy: 0.9764\n",
      "Epoch 33/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0684 - categorical_accuracy: 0.9785 - val_loss: 0.0839 - val_categorical_accuracy: 0.9736\n",
      "Epoch 34/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0661 - categorical_accuracy: 0.9786 - val_loss: 0.0752 - val_categorical_accuracy: 0.9785\n",
      "Epoch 35/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0649 - categorical_accuracy: 0.9800 - val_loss: 0.0763 - val_categorical_accuracy: 0.9743\n",
      "Epoch 36/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0578 - categorical_accuracy: 0.9819 - val_loss: 0.0786 - val_categorical_accuracy: 0.9722\n",
      "Epoch 37/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0537 - categorical_accuracy: 0.9839 - val_loss: 0.0786 - val_categorical_accuracy: 0.9778\n",
      "Epoch 38/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0558 - categorical_accuracy: 0.9818 - val_loss: 0.1196 - val_categorical_accuracy: 0.9653\n",
      "Epoch 39/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0780 - categorical_accuracy: 0.9722 - val_loss: 0.1057 - val_categorical_accuracy: 0.9639\n",
      "Epoch 40/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0631 - categorical_accuracy: 0.9804 - val_loss: 0.0873 - val_categorical_accuracy: 0.9660\n",
      "Epoch 41/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0512 - categorical_accuracy: 0.9842 - val_loss: 0.0813 - val_categorical_accuracy: 0.9722\n",
      "Epoch 42/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0409 - categorical_accuracy: 0.9863 - val_loss: 0.0889 - val_categorical_accuracy: 0.9701\n",
      "Epoch 43/100\n",
      "5760/5760 [==============================] - 98s 17ms/step - loss: 0.0377 - categorical_accuracy: 0.9891 - val_loss: 0.1066 - val_categorical_accuracy: 0.9694\n",
      "Epoch 44/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0386 - categorical_accuracy: 0.9887 - val_loss: 0.1085 - val_categorical_accuracy: 0.9653\n",
      "Epoch 45/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0388 - categorical_accuracy: 0.9878 - val_loss: 0.0964 - val_categorical_accuracy: 0.9715\n",
      "Epoch 46/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0331 - categorical_accuracy: 0.9899 - val_loss: 0.1578 - val_categorical_accuracy: 0.9507\n",
      "Epoch 47/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0454 - categorical_accuracy: 0.9851 - val_loss: 0.1220 - val_categorical_accuracy: 0.9625\n",
      "Epoch 48/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0362 - categorical_accuracy: 0.9884 - val_loss: 0.1100 - val_categorical_accuracy: 0.9701\n",
      "Epoch 49/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0229 - categorical_accuracy: 0.9939 - val_loss: 0.1173 - val_categorical_accuracy: 0.9681\n",
      "Epoch 50/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0285 - categorical_accuracy: 0.9917 - val_loss: 0.1156 - val_categorical_accuracy: 0.9715\n",
      "Epoch 51/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0191 - categorical_accuracy: 0.9957 - val_loss: 0.1192 - val_categorical_accuracy: 0.9687\n",
      "Epoch 52/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0146 - categorical_accuracy: 0.9977 - val_loss: 0.1264 - val_categorical_accuracy: 0.9715\n",
      "Epoch 53/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0145 - categorical_accuracy: 0.9972 - val_loss: 0.1398 - val_categorical_accuracy: 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0176 - categorical_accuracy: 0.9946 - val_loss: 0.1355 - val_categorical_accuracy: 0.9701\n",
      "Epoch 55/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0233 - categorical_accuracy: 0.9932 - val_loss: 0.1494 - val_categorical_accuracy: 0.9667\n",
      "Epoch 56/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0164 - categorical_accuracy: 0.9958 - val_loss: 0.1327 - val_categorical_accuracy: 0.9729\n",
      "Epoch 57/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0110 - categorical_accuracy: 0.9976 - val_loss: 0.1459 - val_categorical_accuracy: 0.9701\n",
      "Epoch 58/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0103 - categorical_accuracy: 0.9981 - val_loss: 0.1634 - val_categorical_accuracy: 0.9674\n",
      "Epoch 59/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0088 - categorical_accuracy: 0.9988 - val_loss: 0.1725 - val_categorical_accuracy: 0.9681\n",
      "Epoch 60/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0074 - categorical_accuracy: 0.9986 - val_loss: 0.1693 - val_categorical_accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0103 - categorical_accuracy: 0.9972 - val_loss: 0.1716 - val_categorical_accuracy: 0.9660\n",
      "Epoch 62/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0865 - categorical_accuracy: 0.9741 - val_loss: 0.1131 - val_categorical_accuracy: 0.9708\n",
      "Epoch 63/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0287 - categorical_accuracy: 0.9924 - val_loss: 0.1056 - val_categorical_accuracy: 0.9708\n",
      "Epoch 64/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0186 - categorical_accuracy: 0.9955 - val_loss: 0.1349 - val_categorical_accuracy: 0.9639\n",
      "Epoch 65/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0127 - categorical_accuracy: 0.9967 - val_loss: 0.1388 - val_categorical_accuracy: 0.9681\n",
      "Epoch 66/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0095 - categorical_accuracy: 0.9981 - val_loss: 0.1404 - val_categorical_accuracy: 0.9681\n",
      "Epoch 67/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0081 - categorical_accuracy: 0.9986 - val_loss: 0.1488 - val_categorical_accuracy: 0.9681\n",
      "Epoch 68/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0064 - categorical_accuracy: 0.9988 - val_loss: 0.1562 - val_categorical_accuracy: 0.9701\n",
      "Epoch 69/100\n",
      "5760/5760 [==============================] - 96s 17ms/step - loss: 0.0064 - categorical_accuracy: 0.9991 - val_loss: 0.1629 - val_categorical_accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "5760/5760 [==============================] - 97s 17ms/step - loss: 0.0067 - categorical_accuracy: 0.9986 - val_loss: 0.1620 - val_categorical_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "acc = []\n",
    "model = han()\n",
    "model.save_weights('model.h5')\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    model.load_weights('model.h5')\n",
    "    \n",
    "    print('\\nFold ',j)\n",
    "    X_train_cv = data[train_idx]\n",
    "    y_train_cv = labels_dummy[train_idx]\n",
    "    X_valid_cv = data[val_idx]\n",
    "    y_valid_cv = labels_dummy[val_idx]\n",
    "    \n",
    "    history = model.fit(X_train_cv, y_train_cv, validation_data=(X_valid_cv, y_valid_cv), \n",
    "                        epochs = 100 , batch_size=400, callbacks=[checkpoint,es])\n",
    "    \n",
    "    y_pred = model.predict(X_valid_cv)\n",
    "    \n",
    "    res.append(precision_recall_fscore_support(y_valid_cv.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    acc.append(accuracy_score(y_valid_cv.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.predict(X_valid_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-16d568470c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'resultados' is not defined"
     ]
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r.argmax(axis=1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.97075209, 0.96814404]),\n",
       "  array([0.96805556, 0.97083333]),\n",
       "  array([0.96940195, 0.96948682]),\n",
       "  array([720, 720])),\n",
       " (array([0.95225102, 0.9688826 ]),\n",
       "  array([0.96944444, 0.95138889]),\n",
       "  array([0.96077082, 0.96005606]),\n",
       "  array([720, 720])),\n",
       " (array([0.98041958, 0.9737931 ]),\n",
       "  array([0.97361111, 0.98055556]),\n",
       "  array([0.97700348, 0.97716263]),\n",
       "  array([720, 720])),\n",
       " (array([0.9762901 , 0.97233748]),\n",
       "  array([0.97222222, 0.97638889]),\n",
       "  array([0.97425191, 0.97435897]),\n",
       "  array([720, 720])),\n",
       " (array([0.96027397, 0.97323944]),\n",
       "  array([0.97361111, 0.95972222]),\n",
       "  array([0.96689655, 0.96643357]),\n",
       "  array([720, 720]))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Precision  PrecisionT    Recall   RecallT    Fscore   FscoreT       Acc\n",
      "0   0.970752    0.968144  0.968056  0.970833  0.969402  0.969487  0.969444\n",
      "   Precision  PrecisionT    Recall   RecallT    Fscore   FscoreT       Acc\n",
      "0   0.970752    0.968144  0.968056  0.970833  0.969402  0.969487  0.969444\n",
      "1   0.952251    0.968883  0.969444  0.951389  0.960771  0.960056  0.960417\n",
      "   Precision  PrecisionT    Recall   RecallT    Fscore   FscoreT       Acc\n",
      "0   0.970752    0.968144  0.968056  0.970833  0.969402  0.969487  0.969444\n",
      "1   0.952251    0.968883  0.969444  0.951389  0.960771  0.960056  0.960417\n",
      "2   0.980420    0.973793  0.973611  0.980556  0.977003  0.977163  0.977083\n",
      "   Precision  PrecisionT    Recall   RecallT    Fscore   FscoreT       Acc\n",
      "0   0.970752    0.968144  0.968056  0.970833  0.969402  0.969487  0.969444\n",
      "1   0.952251    0.968883  0.969444  0.951389  0.960771  0.960056  0.960417\n",
      "2   0.980420    0.973793  0.973611  0.980556  0.977003  0.977163  0.977083\n",
      "3   0.976290    0.972337  0.972222  0.976389  0.974252  0.974359  0.974306\n",
      "   Precision  PrecisionT    Recall   RecallT    Fscore   FscoreT       Acc\n",
      "0   0.970752    0.968144  0.968056  0.970833  0.969402  0.969487  0.969444\n",
      "1   0.952251    0.968883  0.969444  0.951389  0.960771  0.960056  0.960417\n",
      "2   0.980420    0.973793  0.973611  0.980556  0.977003  0.977163  0.977083\n",
      "3   0.976290    0.972337  0.972222  0.976389  0.974252  0.974359  0.974306\n",
      "4   0.960274    0.973239  0.973611  0.959722  0.966897  0.966434  0.966667\n"
     ]
    }
   ],
   "source": [
    "resultados = pd.DataFrame(columns=['Precision', 'PrecisionT', 'Recall', 'RecallT', 'Fscore', 'FscoreT', 'Acc'])\n",
    "for i in range(5):\n",
    "    resultados = resultados.append({'Precision':res[i][0][0], 'PrecisionT':res[i][0][1], \n",
    "                                    'Recall':res[i][1][0], 'RecallT':res[i][1][1], 'Fscore':res[i][2][0], \n",
    "                                    'FscoreT':res[i][2][1], 'Acc':acc[i]},ignore_index=True)\n",
    "    print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.to_csv(\"res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
